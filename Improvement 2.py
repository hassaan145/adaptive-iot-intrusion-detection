# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P_CE-JxGyQL3cJhgs4jgCP0tHnl8lu6i
"""

# ================================================================
#   NSL-KDD  → Base CNN-LSTM+Attention Model vs Dynamic PSO Model
# ================================================================

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
import time, random

# ================================================================
# 1) LOAD NSL-KDD DATA
# ================================================================
TRAIN = "/content/drive/MyDrive/nsl-kdd/KDDTrain+.txt"
TEST  = "/content/drive/MyDrive/nsl-kdd/KDDTest+.txt"

df_train = pd.read_csv(TRAIN, header=None)
df_test  = pd.read_csv(TEST, header=None)

# Combine to handle encoding
df_all = pd.concat([df_train, df_test], ignore_index=True)

# Detect label column (contains 'normal')
label_col = None
for col in df_all.columns[::-1]:
    vals = df_all[col].astype(str).str.lower().unique()
    if any(v == "normal" for v in vals):
        label_col = col
        break

# Binary labels
y_all = (df_all[label_col].astype(str).str.lower() != 'normal').astype(int)

# Drop label & difficulty column
drop_cols = [label_col]
if df_all.shape[1] > 1:
    drop_cols.append(df_all.columns[-1])  # difficulty
X_all = df_all.drop(columns=drop_cols)

# One-hot encoding for categorical
cat_cols = X_all.select_dtypes(include=['object']).columns.tolist()
X_all = pd.get_dummies(X_all, columns=cat_cols, drop_first=True)

X_all = X_all.fillna(0)
X_all = X_all.astype(float)

# Split back
nTrain = len(df_train)
X_train, X_test = X_all.iloc[:nTrain].values, X_all.iloc[nTrain:].values
y_train, y_test = y_all[:nTrain].values, y_all[nTrain:].values

# Scale
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)

print("Final shapes → Train:", X_train.shape, "Test:", X_test.shape)

# ================================================================
# 2) DYNAMIC BINARY PSO FOR FEATURE SELECTION
# ================================================================
class DynamicBinaryPSO:
    def __init__(self, ndim, pop=24, iters=100):
        self.ndim = ndim
        self.pop = pop
        self.iters = iters

    def sigmoid(self, x):
        return 1/(1+np.exp(-x))

    def fitness(self, mask, Xtr, ytr, Xval, yval):
        sel = mask.astype(bool)
        if sel.sum() == 0: return 0
        clf = LogisticRegression(max_iter=200, solver='liblinear')
        try:
            clf.fit(Xtr[:, sel], ytr)
            return clf.score(Xval[:, sel], yval)
        except: return 0

    def run(self, X, y):
        Xtr, Xval, ytr, yval = train_test_split(X, y, test_size=0.25, stratify=y)
        pos = np.random.rand(self.pop, self.ndim)
        vel = np.random.uniform(-1,1,(self.pop,self.ndim))
        pbest = pos.copy()
        pbest_fit = np.zeros(self.pop)
        gbest, gbest_fit = None, -1

        # initial evaluation
        for i in range(self.pop):
            mask = (pos[i] > 0.5).astype(int)
            f = self.fitness(mask, Xtr, ytr, Xval, yval)
            pbest_fit[i] = f
            if f > gbest_fit:
                gbest_fit = f
                gbest = pos[i].copy()

        print("PSO initial best:", gbest_fit)

        # iterations
        for it in range(self.iters):
            w = 0.9 - it*(0.5/self.iters)
            c1 = 2.5 - it*(2.0/self.iters)
            c2 = 0.5 + it*(2.0/self.iters)

            for i in range(self.pop):
                r1 = np.random.rand(self.ndim)
                r2 = np.random.rand(self.ndim)

                vel[i] = w*vel[i] + c1*r1*(pbest[i]-pos[i]) + c2*r2*(gbest-pos[i])
                pos[i] += vel[i]
                pos[i] = np.clip(pos[i], 0, 1)

                # binary selection
                mask = (self.sigmoid(vel[i]) > np.random.rand(self.ndim)).astype(int)

                f = self.fitness(mask, Xtr, ytr, Xval, yval)
                if f > pbest_fit[i]:
                    pbest_fit[i] = f
                    pbest[i] = pos[i].copy()

                if f > gbest_fit:
                    gbest_fit = f
                    gbest = pos[i].copy()

            if (it+1) % 5 == 0:
                print(f"Iter {it+1}/{self.iters}  best={gbest_fit:.4f}")

        return (gbest > 0.5).astype(int)

print("Running Dynamic PSO...")
pso = DynamicBinaryPSO(ndim=X_train.shape[1])
best_mask = pso.run(X_train, y_train)
sel_idx = np.where(best_mask == 1)[0]
print("Selected features:", len(sel_idx))

X_train_sel = X_train[:, sel_idx]
X_test_sel  = X_test[:,  sel_idx]

# ================================================================
# 3) BASE-PAPER MODEL = CNN + BiLSTM + LSTM + Attention
# ================================================================
class AdditiveAttention(nn.Module):
    def __init__(self, hidden):
        super().__init__()
        self.W = nn.Linear(hidden, hidden)
        self.v = nn.Linear(hidden, 1)

    def forward(self, H):  # H: (seq, batch, hidden)
        Ht = H.permute(1,0,2)
        score = self.v(torch.tanh(self.W(Ht)))
        weights = torch.softmax(score, dim=1)
        ctx = torch.sum(weights * Ht, dim=1)
        return ctx

class CNN_LSTM_Attn(nn.Module):
    def __init__(self, nfeat):
        super().__init__()
        self.conv = nn.Conv1d(1, 128, kernel_size=3, padding=1)
        self.pool = nn.MaxPool1d(2)
        self.bilstm = nn.LSTM(128, 64, bidirectional=True)
        self.lstm2  = nn.LSTM(128, 32)
        self.attn = AdditiveAttention(32)
        self.fc = nn.Sequential(
            nn.Linear(32,64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64,2)
        )

    def forward(self, x):
        x = torch.relu(self.conv(x))
        x = self.pool(x)
        x = x.permute(2,0,1)
        H,_ = self.bilstm(x)
        H2,_ = self.lstm2(H)
        ctx = self.attn(H2)
        return self.fc(ctx)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ================================================================
# 4) TRAINING FUNCTION (for both models)
# ================================================================
def train_model(Xtr, ytr, Xte, yte, epochs=10, batch=128):
    model = CNN_LSTM_Attn(Xtr.shape[1]).to(device)
    opt = optim.Adam(model.parameters(), lr=1e-3)
    loss_fn = nn.CrossEntropyLoss()

    train_loader = DataLoader(TensorDataset(
        torch.tensor(Xtr).float().unsqueeze(1),
        torch.tensor(ytr).long()
    ), batch_size=batch, shuffle=True)

    test_loader = DataLoader(TensorDataset(
        torch.tensor(Xte).float().unsqueeze(1),
        torch.tensor(yte).long()
    ), batch_size=batch, shuffle=False)

    acc_hist = []

    for ep in range(epochs):
        model.train()
        for xb,yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            opt.zero_grad()
            pred = model(xb)
            loss = loss_fn(pred, yb)
            loss.backward()
            opt.step()

        # Evaluate
        model.eval()
        ytrue, ypred = [], []
        with torch.no_grad():
            for xb,yb in test_loader:
                xb = xb.to(device)
                out = model(xb).argmax(1).cpu().numpy()
                ypred.extend(out)
                ytrue.extend(yb.numpy())

        acc = accuracy_score(ytrue, ypred)
        acc_hist.append(acc)
        print(f"Epoch {ep+1}/{epochs}  Accuracy={acc:.4f}")

    return acc_hist

# ================================================================
# 5) TRAIN BOTH MODELS
# ================================================================
print("\nTRAINING BASE MODEL...")
acc_base = train_model(X_train, y_train, X_test, y_test)

print("\nTRAINING PSO-SELECTED MODEL...")
acc_pso = train_model(X_train_sel, y_train, X_test_sel, y_test)

# ================================================================
# 6) PLOT COMPARISON
# ================================================================
plt.figure(figsize=(7,5))
plt.plot(acc_base, marker='o', label="Base CNN-LSTM-Attention")
plt.plot(acc_pso,  marker='o', label="Dynamic PSO + CNN-LSTM-Attention")
plt.title("Accuracy Comparison (NSL-KDD)")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(True)
plt.legend()
plt.show()